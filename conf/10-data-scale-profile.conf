#Sleep
#Unit: seconds
hibench.sleep.tiny.mapper.seconds 	3
hibench.sleep.tiny.reducer.seconds 	3
hibench.sleep.small.mapper.seconds 	30
hibench.sleep.small.reducer.seconds 	30
hibench.sleep.large.mapper.seconds 	90
hibench.sleep.large.reducer.seconds 	45
hibench.sleep.huge.mapper.seconds 	90
hibench.sleep.huge.reducer.seconds 	45
hibench.sleep.gigantic.mapper.seconds 	90
hibench.sleep.gigantic.reducer.seconds 	45
hibench.sleep.bigdata.mapper.seconds 	90
hibench.sleep.bigdata.reducer.seconds 	45


#Aggregation
#Unit: record number 
hibench.aggregation.tiny.uservisits		1000
hibench.aggregation.tiny.pages			120
hibench.aggregation.small.uservisits		100000
hibench.aggregation.small.pages			12000
hibench.aggregation.large.uservisits		1000000
hibench.aggregation.large.pages			120000
hibench.aggregation.huge.uservisits		10000000
hibench.aggregation.huge.pages			1200000
hibench.aggregation.gigantic.uservisits		100000000
hibench.aggregation.gigantic.pages		12000000
hibench.aggregation.bigdata.uservisits		800000000
hibench.aggregation.bigdata.pages		9600000

#Scan
#Unit: record number 
hibench.scan.tiny.uservisits			1000
hibench.scan.tiny.pages				120
hibench.scan.small.uservisits			100000
hibench.scan.small.pages			12000
hibench.scan.large.uservisits			1000000
hibench.scan.large.pages			120000
hibench.scan.huge.uservisits			10000000
hibench.scan.huge.pages				1200000
hibench.scan.gigantic.uservisits		100000000
hibench.scan.gigantic.pages			12000000
hibench.scan.bigdata.uservisits			5000000000
hibench.scan.bigdata.pages			10000000


#Join
#Unit: record number
hibench.join.tiny.uservisits			1000
hibench.join.tiny.pages				120
hibench.join.small.uservisits			100000
hibench.join.small.pages			12000
hibench.join.large.uservisits			1000000
hibench.join.large.pages			120000
hibench.join.huge.uservisits			10000000
hibench.join.huge.pages				1200000
hibench.join.gigantic.uservisits		100000000
hibench.join.gigantic.pages			12000000
hibench.join.bigdata.uservisits			5000000000
hibench.join.bigdata.pages			120000000

#Sort
#Unit: bytes of data
hibench.sort.tiny.datasize			32000
hibench.sort.small.datasize			3200000000
hibench.sort.large.datasize			32000000000
hibench.sort.huge.datasize			320000000000
hibench.sort.gigantic.datasize			3200000000000
hibench.sort.bigdata.datasize			300000000000

#Wordcount
#Unit: bytes of data
hibench.wordcount.tiny.datasize			32000
hibench.wordcount.small.datasize		3200000000
hibench.wordcount.large.datasize		32000000000
hibench.wordcount.huge.datasize			320000000000
hibench.wordcount.gigantic.datasize		3200000000000
hibench.wordcount.bigdata.datasize		2000000000000

#Terasort
#Unit: record number of data, 100 bytes per record.
hibench.terasort.tiny.datasize			32000
hibench.terasort.small.datasize			3200000
hibench.terasort.large.datasize			32000000
hibench.terasort.huge.datasize			320000000
hibench.terasort.gigantic.datasize		3200000000
hibench.terasort.bigdata.datasize		3000000000

#Bayes
#Unit: Pages -> Number of article sample 
#Unit: Classes -> Number of model classes
#Unit: ngrams -> N-Grams. Should keep it small
hibench.bayes.tiny.pages			25000
hibench.bayes.tiny.classes			10
hibench.bayes.tiny.ngrams			1
hibench.bayes.small.ngrams			1
hibench.bayes.small.pages			30000
hibench.bayes.small.classes			100
hibench.bayes.small.ngrams			2
hibench.bayes.large.pages			100000
hibench.bayes.large.classes			100
hibench.bayes.large.ngrams			2
hibench.bayes.huge.pages			500000
hibench.bayes.huge.classes			100
hibench.bayes.huge.ngrams			2
hibench.bayes.gigantic.pages			1000000
hibench.bayes.gigantic.classes			100
hibench.bayes.gigantic.ngrams			2
hibench.bayes.bigdata.pages			50000000
hibench.bayes.bigdata.classes			10000
hibench.bayes.bigdata.ngrams			2

#Kmeans
#Unit: num_of_clusters -> cluster number
#Unit: dimemsions -> dimensions of data vector
#Unit: num_of_samples -> total number of data vector
#Unit: samples_per_inputfile -> as name suggests
#Unit: max_iteration -> as name suggests
#Unit: k -> K-means
#Unit: convergedist -> converge distribution coefficient
hibench.kmeans.tiny.num_of_clusters		5
hibench.kmeans.tiny.dimensions			3
hibench.kmeans.tiny.num_of_samples		30000
hibench.kmeans.tiny.samples_per_inputfile	6000
hibench.kmeans.tiny.max_iteration		5
hibench.kmeans.tiny.k				10
hibench.kmeans.tiny.convergedist		0.5
hibench.kmeans.small.num_of_clusters		5
hibench.kmeans.small.dimensions			20
hibench.kmeans.small.num_of_samples		3000000
hibench.kmeans.small.samples_per_inputfile	600000
hibench.kmeans.small.max_iteration		5
hibench.kmeans.small.k				10
hibench.kmeans.small.convergedist		0.5
hibench.kmeans.large.num_of_clusters		5
hibench.kmeans.large.dimensions			20
hibench.kmeans.large.num_of_samples		20000000
hibench.kmeans.large.samples_per_inputfile	4000000
hibench.kmeans.large.max_iteration		5
hibench.kmeans.large.k				10
hibench.kmeans.huge.num_of_clusters		5
hibench.kmeans.huge.dimensions			20
hibench.kmeans.huge.num_of_samples		100000000
hibench.kmeans.huge.samples_per_inputfile	20000000
hibench.kmeans.huge.max_iteration		5
hibench.kmeans.huge.k				10
hibench.kmeans.huge.convergedist		0.5
hibench.kmeans.gigantic.num_of_clusters		5
hibench.kmeans.gigantic.dimensions		20
hibench.kmeans.gigantic.num_of_samples		500000000
hibench.kmeans.gigantic.samples_per_inputfile	100000000
hibench.kmeans.gigantic.max_iteration		5
hibench.kmeans.gigantic.k			10
hibench.kmeans.gigantic.convergedist		0.5
hibench.kmeans.bigdata.num_of_clusters		5
hibench.kmeans.bigdata.dimensions		20
hibench.kmeans.bigdata.num_of_samples		1000000000
hibench.kmeans.bigdata.samples_per_inputfile	100000000
hibench.kmeans.bigdata.max_iteration		10
hibench.kmeans.bigdata.k			10
hibench.kmeans.bigdata.convergedist		0.5

#Pagerank
#Unit: pages -> Total number of pages
#Unit: num_iterations -> as name suggests
#Unit: block -> Use pagerank-plain or pagerank-block
#Unit: block_width -> block width, usually set to 16
hibench.pagerank.tiny.pages			50
hibench.pagerank.tiny.num_iterations		1
hibench.pagerank.tiny.block			0
hibench.pagerank.tiny.block_width		16
hibench.pagerank.small.pages			5000
hibench.pagerank.small.num_iterations		3
hibench.pagerank.small.block			0
hibench.pagerank.small.block_width		16
hibench.pagerank.large.pages			500000
hibench.pagerank.large.num_iterations		3
hibench.pagerank.large.block			0
hibench.pagerank.large.block_width		16
hibench.pagerank.huge.pages			5000000
hibench.pagerank.huge.num_iterations		3
hibench.pagerank.huge.block			0
hibench.pagerank.huge.block_width		16
hibench.pagerank.gigantic.pages			50000000
hibench.pagerank.gigantic.num_iterations	3
hibench.pagerank.gigantic.block			0
hibench.pagerank.gigantic.block_width		16
hibench.pagerank.bigdata.pages			50000000
hibench.pagerank.bigdata.num_iterations		3
hibench.pagerank.bigdata.block			0
hibench.pagerank.bigdata.block_width		16

#Nutchindexing
#Unit: pages -> Number of pages
hibench.nutch.tiny.pages			25000
hibench.nutch.small.pages			1000000
hibench.nutch.large.pages			10000000
hibench.nutch.huge.pages			100000000
hibench.nutch.gigantic.pages			1000000000
hibench.nutch.bigdata.pages			100000000000

#DFSIOE
#Unit: number_of_file -> as name suggests
#Unit: filesize -> MB of file size
hibench.dfsioe.tiny.read.number_of_files	16
hibench.dfsioe.tiny.read.file_size		1
hibench.dfsioe.tiny.write.number_of_files	16
hibench.dfsioe.tiny.write.file_size		1

hibench.dfsioe.small.read.number_of_files	32
hibench.dfsioe.small.read.file_size		10
hibench.dfsioe.small.write.number_of_files	32
hibench.dfsioe.small.write.file_size		10

hibench.dfsioe.large.read.number_of_files	64
hibench.dfsioe.large.read.file_size		10
hibench.dfsioe.large.write.number_of_files	64
hibench.dfsioe.large.write.file_size		10

hibench.dfsioe.huge.read.number_of_files	256
hibench.dfsioe.huge.read.file_size		100
hibench.dfsioe.huge.write.number_of_files	256
hibench.dfsioe.huge.write.file_size		100

hibench.dfsioe.gigantic.read.number_of_files	512
hibench.dfsioe.gigantic.read.file_size		400
hibench.dfsioe.gigantic.write.number_of_files	512
hibench.dfsioe.gigantic.write.file_size		400

hibench.dfsioe.bigdata.read.number_of_files	2048
hibench.dfsioe.bigdata.read.file_size		1000
hibench.dfsioe.bigdata.write.number_of_files	2048
hibench.dfsioe.bigdata.write.file_size		1000
