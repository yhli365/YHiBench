#!/usr/bin/env python
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.




# NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE #
#                                                                       #
# This conf file is part of hibench distribution, provided for a        #
# definition of and clarify base configuration for internal mechanism   #
# of hibench and not intended for modifications by users.               #
#                                                                       #
# Any configuration should goes on 99-user_defined_properties.conf.     #
#                                                                       #
# NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE NOTE #




#======================================================
# basic hadoop conf
#======================================================

# default hadoop executable path
hibench.hadoop.executable	${hibench.hadoop.home}/bin/hadoop

#======================================================
# basic spark conf
#======================================================

# Empty values, will probe automatically. If auto-probe failed, please
# set the correct values in 99-user_defined_properties.conf
hibench.hadoop.version
hibench.hadoop.release
hibench.hadoop.configure.dir
hibench.spark.version
hibench.masters.hostnames
hibench.slaves.hostnames
hibench.dfsioe.map.java_opts	
hibench.dfsioe.red.java_opts

# default spark master if unspecified
hibench.spark.master		local[1]

#======================================================
# Report files
#======================================================

# default report formats
hibench.report.formats		"%-12s %-10s %-8s %-20s %-20s %-20s %-20s\n"

# default report dir path
hibench.report.dir		${hibench.home}/report

# default report file name
hibench.report.name		hibench.report

#======================================================
# basic sparkbench jars
#======================================================

hibench.dependency.dir		${hibench.home}/src
hibench.sparkbench.jar		${hibench.home}/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-${hibench.hadoop.version.mr}-${hibench.spark.version}-jar-with-dependencies.jar

# convert table:
# hibench.hadoop.version          hibench.hadoop.version.mr
#       hadoop1            ->            MR1
#       hadoop2            ->            MR2
hibench.hadoop.version.mr	${hibench.consts.mr.${hibench.hadoop.version}}
hibench.consts.mr.hadoop1	MR1
hibench.consts.mr.hadoop2	MR2

# hibench config folder
hibench.configure.dir		${hibench.home}/conf

# sparkbench python workloads
hibench.sparkbench.python.dir	${hibench.home}/src/sparkbench/src/main/python

# default hibench HDFS root
hibench.hdfs.data.dir		${hibench.hdfs.master}/HiBench

# path of hibench datatools
hibench.hibench.datatool.dir	${hibench.home}/src/autogen/target/autogen-4.0-SNAPSHOT-jar-with-dependencies.jar

# jar of sleep job (which is different for hadoop1/2, and apache/cdh
# release) it'll auto probed by python scripts. However, you can
# explicitly define here:
hibench.sleep.job.jar

# default values of hibench mapper/reducer workloads
hibench.default.map.parallelism		2
hibench.default.shuffle.parallelism	2

# Default YARN resource configuration
hibench.yarn.executor.num	1
hibench.yarn.executor.cores	1
hibench.yarn.executor.memory	${spark.executor.memory}
hibench.yarn.driver.memory	${spark.driver.memory}

#======================================================
# workload home/input/ouput path
#======================================================

hibench.hive.home		${hibench.dependency.dir}/hivebench/target/${hibench.hive.release}
hibench.hive.release		hive-0.12.0-bin
hibench.hivebench.template.dir	${hibench.dependency.dir}/hivebench/hive_template
hibench.hive.dir.name.input	${hibench.workload.dir.name.input}
hibench.hive.dir.name.ouput	${hibench.workload.dir.name.output}
hibench.kmeans.dir.name.input	${hibench.workload.dir.name.input}
hibench.kmeans.dir.name.output	${hibench.workload.dir.name.output}
hibench.bayes.dir.name.input	${hibench.workload.dir.name.input}
hibench.bayes.dir.name.output	${hibench.workload.dir.name.output}
hibench.pagerank.dir.name.input		${hibench.workload.dir.name.input}
hibench.pagerank.dir.name.output	${hibench.workload.dir.name.output}
hibench.pagerank.pegasus.dir		${hibench.dependency.dir}/pegasus/target/pegasus-2.0-SNAPSHOT.jar
hibench.mahout.home		${hibench.dependency.dir}/mahout/target/${hibench.mahout.release}
hibench.mahout.release.apache   mahout-distribution-0.9
hibench.mahout.release.cdh4	mahout-0.7-cdh4.7.1
hibench.mahout.release.cdh5	mahout-0.9-cdh5.1.0
hibench.mahout.release		${hibench.mahout.release.${hibench.hadoop.release}}

hibench.nutch.dir.name.input	${hibench.workload.dir.name.input}
hibench.nutch.dir.name.output	${hibench.workload.dir.name.output}
hibench.nutch.nutchindexing.dir	${hibench.dependency.dir}/nutchindexing/
hibench.nutch.release		nutch-1.2
hibench.nutch.home		${hibench.dependency.dir}/nutchindexing/target/${hibench.nutch.release}

hibench.dfsioe.dir.name.input	${hibench.workload.dir.name.input}
hibench.dfsioe.dir.name.output	${hibench.workload.dir.name.output}

hibench.randomtextwriter.bytestotal.hadoop1.name   test.randomtextwrite.total_bytes
hibench.randomtextwriter.bytestotal.hadoop2.name   mapreduce.randomtextwriter.totalbytes
hibench.randomtextwriter.bytestotal.name	   ${hibench.randomtextwriter.bytestotal.${hibench.hadoop.version}.name}

# Workload Input/Output name setting for compress/uncompress mode
hibench.workload.dir.name.compress_disable.input	Input
hibench.workload.dir.name.compress_disable.output	Output
hibench.workload.dir.name.compress_enable.input		Input-comp-${hibench.compress.codec.profile}
hibench.workload.dir.name.compress_enable.output	Output-comp-${hibench.compress.codec.profile}

hibench.workload.dir.name.input				${hibench.workload.dir.name.compress_${hibench.compress.profile}.input}
hibench.workload.dir.name.output			${hibench.workload.dir.name.compress_${hibench.compress.profile}.output}

#======================================================
# Compression configurations
#======================================================

# compression options for hadoop
hibench.workload.compress.enable.options	"-D ${hibench.compress.map.output.compress.name}=true -D ${hibench.compress.map.output.compress.codec.name}=${hibench.compress.map.output.compress.codec.value} -D ${hibench.compress.output.fileoutputformat.compress.name}=true -D ${hibench.compress.output.fileoutputformat.compress.codec.name}=${hibench.compress.output.fileoutputformat.compress.codec.value} -D ${hibench.compress.output.fileoutputformat.compress.type.name}=BLOCK"
hibench.workload.compress.disable.options	"-D ${hibench.compress.output.fileoutputformat.compress.name}=false"
hibench.workload.compress.options	 	${hibench.workload.compress.${hibench.compress.profile}.options}

# compression options for datatools
hibench.workload.compress.enable.datatools.options	"-c ${hibench.compress.map.output.compress.codec.value}"
hibench.workload.compress.disable.datatools.options
hibench.workload.compress.datatools.options		${hibench.workload.compress.${hibench.compress.profile}.datatools.options}

# compression options for kmeans generator
hibench.workload.compress.enable.kmeans_gen.options	"-compress true -compressCodec ${hibench.compress.map.output.compress.codec.value} -compressType BLOCK"
hibench.workload.compress.disable.kmeans_gen.options	"-compress false"
hibench.workload.compress.kmeans_gen.options		${hibench.workload.compress.${hibench.compress.profile}.kmeans_gen.options}

# compression options for hive
hibench.workload.compress.enable.hive.options		set hive.exec.compress.output=true; ${hibench.workload.compress.hive.${hibench.hadoop.version}.options}
hibench.workload.compress.disable.hive.options
hibench.workload.compress.hive.hadoop1.options		set ${hibench.compress.output.fileoutputformat.compress.name}=true; set ${hibench.compress.output.fileoutputformat.compress.type.name}=BLOCK; set ${hibench.compress.map.output.compress.codec.name}=${hibench.compress.map.output.compress.codec.value};
hibench.workload.compress.hive.hadoop2.options		set mapreduce.jobtracker.address=ignorethis; set hive.exec.show.job.failure.debug.info=false; set ${hibench.compress.map.output.compress.codec.name}=true; set ${hibench.compress.map.output.compress.codec.name}=${hibench.compress.map.output.compress.codec.value}; set ${hibench.compress.output.fileoutputformat.compress.name}=true; set ${hibench.compress.output.fileoutputformat.compress.codec.name}=${hibench.compress.output.fileoutputformat.compress.codec.value}; set ${hibench.compress.output.fileoutputformat.compress.type.name}=BLOCK;
hibench.workload.compress.hive.options			"${hibench.workload.compress.${hibench.compress.profile}.hive.options}"

#compression options for sparkbecnh
sparkbench.codec.selection			${sparkbench.codec.${hibench.compress.profile}.options}
sparkbench.codec.disable.options		None
sparkbench.codec.enable.options			${hibench.compress.codec}

hibench.compress.map.output.compress.hadoop1.name			mapred.map.output.compress
hibench.compress.map.output.compress.codec.hadoop1.name			mapred.map.output.compress.codec
hibench.compress.output.fileoutputformat.compress.hadoop1.name		mapred.output.compress
hibench.compress.output.fileoutputformat.compress.codec.hadoop1.name	mapred.output.compression.codec
hibench.compress.output.fileoutputformat.compress.type.hadoop1.name	mapred.output.compression.type

hibench.compress.map.output.compress.hadoop2.name			mapreduce.map.output.compress
hibench.compress.map.output.compress.codec.hadoop2.name			mapreduce.map.output.compress.codec
hibench.compress.output.fileoutputformat.compress.hadoop2.name		mapreduce.output.fileoutputformat.compress
hibench.compress.output.fileoutputformat.compress.codec.hadoop2.name	mapreduce.output.fileoutputformat.compress.codec
hibench.compress.output.fileoutputformat.compress.type.hadoop2.name	mapreduce.output.fileoutputformat.compress.type

hibench.compress.map.output.compress.name				${hibench.compress.map.output.compress.${hibench.hadoop.version}.name}
hibench.compress.map.output.compress.codec.name				${hibench.compress.map.output.compress.codec.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.name			${hibench.compress.output.fileoutputformat.compress.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.codec.name		${hibench.compress.output.fileoutputformat.compress.codec.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.type.name		${hibench.compress.output.fileoutputformat.compress.type.${hibench.hadoop.version}.name}

hibench.compress.map.output.compress.codec.value			${hibench.compress.codec.map}
hibench.compress.output.fileoutputformat.compress.codec.value		${hibench.compress.codec}


#======================================================
# Default profile selections for data scale & compression
#======================================================

# Compression codec profile relation
hibench.compress.codec			${hibench.compress.${hibench.compress.codec.profile}.codec}
# map codec share with global compression codec
hibench.compress.codec.map		${hibench.compress.${hibench.compress.codec.profile}.codec}

# Avaiable compress codec profiles
hibench.compress.snappy.codec		org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.default.codec		org.apache.hadoop.io.compress.DefaultCodec
hibench.compress.lzo.codec		com.hadoop.compression.lzo.LzoCodec

# Default data scale profile selections. Available options: tiny, small, large, ..., defined in 10-data-scale-profile.conf
hibench.scale.profile  	      	     	tiny
# Default compression options selection: enable, disable
hibench.compress.profile	 	enable
# Default compression codec profile selection:	 snappy, lzo, default
hibench.compress.codec.profile		snappy

#======================================================
# Outputformat settings
#======================================================

# input/output format settings, not heavily tested. DO NOT MODIFY
# Available formats: Text, Sequence. Defaults: Text
# Specifiy Compress codec, None -> no compress. Defaults: None
sparkbench.inputformat         Sequence
sparkbench.inputformat.codec   ${sparkbench.codec.selection}

sparkbench.outputformat        Sequence
sparkbench.outputformat.codec  ${sparkbench.codec.selection}

#======================================================
# Export hibench configurations to spark properties
#======================================================

# set spark parallelism property according to hibench's parallelism value
spark.default.parallelism     ${hibench.default.map.parallelism}

# set spark sql's default shuffle partitions according to hibench's parallelism value
spark.sql.shuffle.partitions  ${hibench.default.map.parallelism}
